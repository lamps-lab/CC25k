input_index,input_context,input_file_key,input_first_author,worker_id_w1,work_time_in_seconds_w1,label_w1,worker_id_w2,work_time_in_seconds_w2,label_w2,worker_id_w3,work_time_in_seconds_w3,label_w3,batch,majority_vote,majority_agreement,lemos_label,temp_label_3/3
1,"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",RS_141_ICDAR_2018_08,First Author: Khan,A18LFH7XW61JO9,8,Neutral,A2HM35CWB7IIFM,4,Negative,A1FVXS8IM5QYO8,6,Negative,batch_26,Negative,2,Negative,OK
1,justified the straight-through-estimator (STE) method used for training the BNNs through bayesian learning [22].,RS_098_MLRC_2020_05,First Author: Meng,A3NAHN61XJ3ZAT,8,Neutral,A2HM35CWB7IIFM,4,Positive,A1G94QON7A9K0N,13,Neutral,batch_11,Neutral,2,Neutral,OK
2,"We selected SADNet [25], which represents a small network based on the UNet improvement, and Restormer, with a more complex network and better fitting abilities, as the night defogging network.",RS_105_MLRC_2020_12,First Author: Chang,A2R2YZTSME1K3F,80,Positive,A3NAHN61XJ3ZAT,8,Neutral,A2HM35CWB7IIFM,5,Positive,batch_16,Positive,2,Positive,OK
3,Chefer et al. [2021] improved the visualization quality of attention-rollout and enabled generating class specific activation map with relevance information but it requires gradient information so it cannot be used for supporting explainability in inference time.,RS_049_MLRC_2021_04,First Author: Chefer,A18LFH7XW61JO9,18,Neutral,A1G94QON7A9K0N,23,Negative,A3NAHN61XJ3ZAT,11,Negative,batch_7,Negative,2,Negative,OK
3,This is achieved in our works using a binary neural network [14].,RS_119_NeurIPS_2019_02,First Author: Helwegen,A18LFH7XW61JO9,13,Neutral,A3NAHN61XJ3ZAT,6,Neutral,A2HM35CWB7IIFM,4,Positive,batch_18,Neutral,2,Neutral,OK
3,"a-b, Multiple methods (the proposed likelihood ratio ranking, integrated gradients [26; 27], and Hotspot [28]) were applied to rank the genes in our simulated dataset by how strongly they were captured by multiGroupVIs group-specific latent spaces.",RS_004_MLRC_2022_04,First Author: Crabbe,A37WXDYYT7RCZ0,8,Neutral,AKSJ3C5O3V9RB,4494,Positive,A5V3ZMQI0PU3F,32,Positive,batch_1,Positive,2,Positive,OK
4,"Even though there are many techniques to achieve such functionality, LSTM has been shown to achieve exceptional success due to its capability of learning both short and long term dependencies of the problem and also designed to deal with vanishing gradient problem which most of the RNN architectures suffer from [28].",RS_133_ICLR_2019_05,First Author: Arpit,A2R2YZTSME1K3F,100,Neutral,A2HM35CWB7IIFM,4,Positive,A2QD9PJUKW7PKK,61,Neutral,batch_25,Neutral,2,Neutral,OK
6,"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",RS_142_ICDAR_2018_09,First Author: Raja,A18LFH7XW61JO9,28,Neutral,A2HM35CWB7IIFM,3,Negative,A1G94QON7A9K0N,9,Negative,batch_26,Negative,2,Negative,OK
7,"Following the methodology described in [5], we employ the OSNet architecture as the backbone for our experiments.",RS_002_MLRC_2022_02,First Author: Zhang,A18LFH7XW61JO9,116,Positive,A2R2YZTSME1K3F,33,Positive,A1NF6PELRKACS9,13,Positive,batch_1,Positive,3,Positive,OK
8,"Discussions around AI equity have focused on the issues arising from uncertainty [9], such as: how AI systems arrive at determi-",RS_078_MLRC_2021_33,First Author: Lee,A3NAHN61XJ3ZAT,10,Neutral,A18LFH7XW61JO9,11,Neutral,A1G94QON7A9K0N,231,Neutral,batch_10,Neutral,3,Neutral,OK
12,"1, we further integrate the stepsize adjusting mechanism proposed in [6] and finally propose a new optimizer named AdaPlus.",RS_054_MLRC_2021_09,First Author: Zhuang,A2QD9PJUKW7PKK,85,Positive,A18LFH7XW61JO9,44,Positive,A1G94QON7A9K0N,20,Positive,batch_7,Positive,3,Positive,OK
13,"In order to estimate the gradient in Equation 19, we leverage the reparameterization trick via the Gumbel-Softmax (GS) distribution (Jang et al., 2016; Meng et al., 2020).",RS_098_MLRC_2020_05,First Author: Meng,A3NAHN61XJ3ZAT,5,Neutral,A1G94QON7A9K0N,13,Positive,AKSJ3C5O3V9RB,372,Positive,batch_11,Positive,2,Positive,OK
14,"sampling estimator, it has been reported in several subsequent data valuation studies that the actual performance of the Group Testing-based estimator does not observably outperform permutation sampling technique [Wang et al., 2020, Yan and Procaccia, 2020, Wang et al., 2021, Wang and Jia, 2023].",RS_032_MLRC_2022_32,First Author: Yan,A5V3ZMQI0PU3F,33,Negative,A2R2YZTSME1K3F,67,Negative,AKSJ3C5O3V9RB,46371,Negative,batch_1,Negative,3,Negative,OK
15,"We also run on other tasks including visual navigation, 2-DOF configuration space manipulation, and 2-DOF workspace manipulation, where all these tasks can be represented as taking a form of map signal over grid Z(2), as previously been done (Zhao et al., 2022; Chaplot et al., 2021).",RS_079_MLRC_2021_34,First Author: Chaplot,A3NAHN61XJ3ZAT,15,Neutral,A18LFH7XW61JO9,32,Positive,A1G94QON7A9K0N,14,Positive,batch_10,Positive,2,Positive,OK
17,"This sensitivity makes them susceptible to manipulations designed to hide the use of problematic features in the AI decision-making and deceive the human overseeing the system [7, 11, 28, 65, 92].",RS_099_MLRC_2020_06,First Author: Pruthi,A3NAHN61XJ3ZAT,7,Neutral,A1G94QON7A9K0N,15,Negative,A2HM35CWB7IIFM,4,Negative,batch_11,Negative,2,Neutral,ISSUE
18,"However, using information from raw attention poses limitations to the complete use of the structural characteristics of vision transformers, which include multiple learning modules [24].",RS_099_MLRC_2020_06,First Author: Pruthi,A3NAHN61XJ3ZAT,14,Negative,A2HM35CWB7IIFM,5,Negative,A1G94QON7A9K0N,23,Neutral,batch_11,Negative,2,Neutral,ISSUE
19,"In this section, we conduct comprehensive experiments to research and answer two key questions: 1) Is the proposed LORE able to effectively predict the logical locations of table cells from input images? 2) Does the LORE framework, modeling TSR as logical location regression, overcome the limitations and cover the abilities of other paradigms? For the first question, we compare LORE with baselines directly predicting logical locations (Xue, Li, and Tao 2019; Xue et al. 2021).",RS_144_ICDAR_2018_11,First Author: Xue,A18LFH7XW61JO9,46,Positive,A2HM35CWB7IIFM,4,Positive,A1G94QON7A9K0N,8,Positive,batch_26,Positive,3,Positive,OK
23,"Then, we borrow and revise the feature attribution strategy of counterfactual analysis (Lang et al. 2021; Zhang, Wang, and Sang 2022) to measure the importance of proxy features by counterfactually changing the proxy features:c = Yc(x, pb) Yc(x, anchor) (6) Where c indicates the importance of",RS_066_MLRC_2021_21,First Author: Lang,A3NAHN61XJ3ZAT,13,Neutral,A18LFH7XW61JO9,16,Neutral,A2R2YZTSME1K3F,51,Positive,batch_10,Neutral,2,Positive,ISSUE
24,"cost (Morcos et al., 2019) including memory consumption and inference time, and additionally enable wide-spread democratization of DNNs with a low carbon footprint.",RS_127_NeurIPS_2019_10,"Cited Paper: (Morcos et al., 2019)",A18LFH7XW61JO9,26,Neutral,A2R2YZTSME1K3F,98,Neutral,A1G94QON7A9K0N,30,Neutral,batch_24,Neutral,3,Neutral,OK
24,"Due to the rapid development of deep learning in documents, many deep learning-based TSR approaches [37, 3, 35, 25] have been presented.",RS_142_ICDAR_2018_09,First Author: Raja,A18LFH7XW61JO9,12,Neutral,A2R2YZTSME1K3F,49,Neutral,A2HM35CWB7IIFM,3,Positive,batch_26,Neutral,2,Neutral,OK
25,A numerical comparison with the fair k-means algorithm proposed in [32] further confirms the robustness and efficiency of the proposed algorithm in constructing informative and high-quality trade-offs.,RS_059_MLRC_2021_14,First Author: Ziko,A2R2YZTSME1K3F,136,Positive,A18LFH7XW61JO9,17,Positive,A3NAHN61XJ3ZAT,6,Neutral,batch_9,Positive,2,Positive,OK
28,"Unfortunately, these approaches either do not explicitly learn sparse features (Barello et al., 2018) or rely on relaxations that can lead to poor gradient estimation during training (Tonolini et al., 2020).",RS_131_ICLR_2019_03,"Cited Paper: (Tonolini et al., 2020)",A2R2YZTSME1K3F,48,Neutral,A2QD9PJUKW7PKK,112,Negative,A2HM35CWB7IIFM,4,Negative,batch_25,Negative,2,Negative,OK
28,"Following (Mangalam et al., 2021), we extract trajectories with a time step 0.4 seconds and obtain 20-frame samples for an 8/12 setting, i.e., given the first 8 frames (3.2 seconds, th = 7), we aim to predict the future 12 frame trajectories (4.8 seconds, tf = 12).",RS_082_MLRC_2021_37,"Cited Paper: (Mangalam et al., 2021)",A3NAHN61XJ3ZAT,9,Neutral,A18LFH7XW61JO9,11,Positive,A2R2YZTSME1K3F,66,Positive,batch_10,Positive,2,Positive,OK
30,"However, incorrect predictions can introduce noise and heavily degrade model training [81, 89].",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,8,Negative,A1G94QON7A9K0N,10,Neutral,A2HM35CWB7IIFM,5,Negative,batch_12,Negative,2,Neutral,ISSUE
31,"We seek to replicate the Antoniak and Mimno [1] paper, hereafter referred to as the original paper/work.",RS_085_MLRC_2021_40,First Author: Antoniak,A2HM35CWB7IIFM,7,Positive,A3NAHN61XJ3ZAT,12,Positive,A5V3ZMQI0PU3F,57,Positive,batch_11,Positive,3,Positive,OK
31,"Hsieh et al. (2019) even have convergence guarantees for their method, something rare in deep learning.",RS_132_ICLR_2019_04,First Author: Hsieh,A2QD9PJUKW7PKK,60,Positive,A2R2YZTSME1K3F,103,Neutral,A18LFH7XW61JO9,130,Neutral,batch_25,Neutral,2,Neutral,OK
32,"One of the common practices in knowledge distillation is employing ensembles as a teacher model (Malinin et al., 2020; Ryabinin et al., 2021) based on the superior performance of the ensemble of deep neural networks (Lakshminarayanan et al., 2017; Ovadia et al., 2019), and several works already",RS_103_MLRC_2020_10,First Author: Malinin,A18LFH7XW61JO9,12,Neutral,A3NAHN61XJ3ZAT,14,Neutral,A2R2YZTSME1K3F,30,Neutral,batch_15,Neutral,3,Neutral,OK
32,934 - - - - - ReS2TIM [36] ICDAR 2013 0.,RS_136_ICDAR_2018_03,First Author: Xue,A18LFH7XW61JO9,10,Neutral,A2HM35CWB7IIFM,3,Neutral,A1G94QON7A9K0N,6,Neutral,batch_26,Neutral,3,Neutral,OK
34,"As a side note, the Shapley value estimated by Permutation sampling is superior to the Least core estimated by Monte-Carlo algorithm, which does not agree with the experiment results in Yan & Procaccia (2020).",RS_032_MLRC_2022_32,First Author: Yan,A2R2YZTSME1K3F,58,Negative,A5V3ZMQI0PU3F,65,Positive,AKSJ3C5O3V9RB,12,Negative,batch_1,Negative,2,Negative,OK
36,"Following the methodology proposed in [34], a fixed threshold of 0.",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,10,Positive,A1G94QON7A9K0N,15,Positive,A2HM35CWB7IIFM,4,Positive,batch_12,Positive,3,Positive,OK
39,"In addition, prominent examples in HCCV research demonstrate disparate algorithmic performance based on race and skin color [106, 293, 125, 327, 217, 34, 33, 261, 236, 44, 122].",RS_021_MLRC_2022_21,First Author: Hirota,A18LFH7XW61JO9,49,Neutral,A5V3ZMQI0PU3F,47,Neutral,AKSJ3C5O3V9RB,44424,Neutral,batch_1,Neutral,3,Neutral,OK
40,(6) SubgraphX (Yuan et al. 2021) provides subgraph-level explanations.,RS_041_MLRC_2022_41,Cited Paper: (Yuan et al. 2021),A2HM35CWB7IIFM,6,Neutral,A5V3ZMQI0PU3F,22,Neutral,A3NAHN61XJ3ZAT,6,Neutral,batch_6,Neutral,3,Neutral,OK
40,"However, as indicated by (Su et al. 2019), episode technique might discard semantic information that is irrelevant for base classes but critical for novel classes.",RS_048_MLRC_2021_03,Cited Paper: (Su et al. 2019),A2QD9PJUKW7PKK,123,Neutral,A1G94QON7A9K0N,24,Negative,A3NAHN61XJ3ZAT,11,Neutral,batch_7,Neutral,2,Neutral,OK
41,"We use ZSKT (Micaelli & Storkey, 2019), CMI (Fang et al., 2021), and OOD (Asano & Saeed, 2021) as the baseline distillation methods.",RS_124_NeurIPS_2019_07,"Cited Paper: (Micaelli & Storkey, 2019)",A2R2YZTSME1K3F,31,Positive,A1G94QON7A9K0N,13,Positive,AKSJ3C5O3V9RB,227,Positive,batch_22,Positive,3,Positive,OK
43,"Based on EFDM, the authors of (Zhang et al., 2022) also propose EFDMix, which replaces the concept of AdaIN in MixStyle with EFDM, in a channel-wise manner as follows: EFDMix(x)i = xi + (1 )yi .",RS_002_MLRC_2022_02,"Cited Paper: (Zhang et al., 2022)",A5V3ZMQI0PU3F,54,Positive,A18LFH7XW61JO9,196,Positive,A2R2YZTSME1K3F,40,Neutral,batch_1,Positive,2,Positive,OK
43,"For pre-training of PE module, we used the same parameter setting as [11].",RS_053_MLRC_2021_08,First Author: Li,A2QD9PJUKW7PKK,42,Positive,A1G94QON7A9K0N,18,Positive,A2HM35CWB7IIFM,3,Positive,batch_7,Positive,3,Positive,OK
44,"As we pointed in Section VI, we cannot be sure that we reproduce results from [17] because the paper contains omissions.",RS_132_ICLR_2019_04,First Author: Hsieh,A2R2YZTSME1K3F,50,Negative,A2QD9PJUKW7PKK,40,Negative,A3EG4C9T4F5DUR,13,Negative,batch_25,Negative,3,Negative,OK
45,"While some of these have been studied in previous works and mitigations are included (Dinan et al., 2019), we",RS_058_MLRC_2021_13,"Cited Paper: (Dinan et al., 2019)",A3NAHN61XJ3ZAT,10,Neutral,A18LFH7XW61JO9,33,Neutral,A2QD9PJUKW7PKK,61,Neutral,batch_9,Neutral,3,Neutral,OK
47,"However, even the T5-3B model only achieves about 70% accuracy (Shaw et al. 2021; Scholak, Schucher, and Bahdanau 2021).",RS_044_MLRC_2022_44,First Author: Shaw,A3NAHN61XJ3ZAT,8,Neutral,A2HM35CWB7IIFM,4,Negative,A1G94QON7A9K0N,21,Negative,batch_6,Negative,2,Neutral,ISSUE
50,", 2014), attention-based (Mohankumar et al., 2020; Tutek and najder, 2020; Ghaeini et al., 2018; Lee et al., 2017), and occlusion-based (DeYoung et al.",RS_115_MLRC_2020_22,First Author: Mohankumar,A18LFH7XW61JO9,9,Neutral,A3NAHN61XJ3ZAT,5,Neutral,A2R2YZTSME1K3F,29,Neutral,batch_18,Neutral,3,Neutral,OK
51,"Moreover, photo-realistic synthesis remains challenging [26, 42].",RS_091_MLRC_2021_46,First Author: Shi,A2QD9PJUKW7PKK,42,Neutral,A3NAHN61XJ3ZAT,4,Neutral,A2HM35CWB7IIFM,14,Negative,batch_11,Neutral,2,Neutral,OK
58,"For this, we reproduced an experiment by Antoniak and Mimno [1] ranking the cosine similarity between 155",RS_085_MLRC_2021_40,First Author: Antoniak,A2HM35CWB7IIFM,3,Positive,A1G94QON7A9K0N,15,Positive,A3NAHN61XJ3ZAT,11,Positive,batch_11,Positive,3,Positive,OK
59,We conducted a reproducibility study of the paper Exacerbating Algorithmic Bias through Fairness Attacks [11].,RS_067_MLRC_2021_22,First Author: Mehrabi,A3NAHN61XJ3ZAT,10,Positive,A18LFH7XW61JO9,8,Positive,A2R2YZTSME1K3F,83,Positive,batch_10,Positive,3,Positive,OK
63,"We will introduce a loss which learns an approximate model m, which can then be combined with the replay buffer D to use both experienced transitions and modelled transitions to learn , as was done in e.g. Sutton (1991) or Janner et al. (2019).",RS_125_NeurIPS_2019_08,First Author: Janner,A2R2YZTSME1K3F,32,Positive,A2HM35CWB7IIFM,4,Positive,A1G94QON7A9K0N,42,Positive,batch_22,Positive,3,Positive,OK
69,"The resulting model errors can impact the learned policy [58, 35, 57, 65, 44, 32, 38] leading to worse performance.",RS_125_NeurIPS_2019_08,First Author: Janner,A1G94QON7A9K0N,386,Negative,A5V3ZMQI0PU3F,73,Neutral,A2HM35CWB7IIFM,3,Negative,batch_22,Negative,2,Negative,OK
75,"GANSpace [Hrknen et al. 2020] attempts to analyze the GAN space by identifying latent directions based on principal component analysis (PCA), applied either in latent space or feature space.",RS_055_MLRC_2021_10,First Author: Härkönen,A2HM35CWB7IIFM,5,Neutral,A18LFH7XW61JO9,5,Neutral,A1G94QON7A9K0N,18,Neutral,batch_8,Neutral,3,Neutral,OK
83,"Our empirical studies on three tasks show that the group with the least standard performance is of the worst adversarial robustness, consistent with prior studies on other datasets [25,44].",RS_061_MLRC_2021_16,First Author: Xu,A2R2YZTSME1K3F,98,Positive,A18LFH7XW61JO9,6,Neutral,A3NAHN61XJ3ZAT,10,Neutral,batch_9,Neutral,2,Neutral,OK
84,"In our experiments, for mixup, we follow the setting in [19] to use  = 0.",RS_128_NeurIPS_2019_11,First Author: Thulasidasan,A2R2YZTSME1K3F,95,Positive,A18LFH7XW61JO9,22,Positive,A1G94QON7A9K0N,9,Positive,batch_24,Positive,3,Positive,OK
87,"For the DM setting, we choose (t) to be a geometric series, following [27].",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,9,Positive,A2HM35CWB7IIFM,4,Positive,AKSJ3C5O3V9RB,300,Positive,batch_18,Positive,3,Positive,OK
88,"In practice,  (j) i is typically represented by the day-of-year [8, 12], and makes it possible to account for the irregular temporal sampling of most satellites.",RS_112_MLRC_2020_19,First Author: Garnot,AJ0RL2YCXZC25,15,Neutral,A3NAHN61XJ3ZAT,8,Neutral,A2R2YZTSME1K3F,38,Neutral,batch_17,Neutral,3,Neutral,OK
89,"The second representative family of mitigation methods is based on explainability [13, 14, 15, 24].",RS_101_MLRC_2020_08,First Author: Singh,A3NAHN61XJ3ZAT,5,Neutral,A1G94QON7A9K0N,9,Positive,AKSJ3C5O3V9RB,182,Neutral,batch_12,Neutral,2,Neutral,OK
94,"In [13], a variant of the snake activation function is used where (z) = z + sin z and this contains infinitely many unsafe points, b = n for n W  b(z) = (n + z) (n) = ( n + z) + sin(n + z) n  sin(n) = (1) sin(z) which is clearly an odd function.",RS_096_MLRC_2020_03,First Author: Ziyin,A3NAHN61XJ3ZAT,4,Neutral,A2QD9PJUKW7PKK,32,Neutral,A18LFH7XW61JO9,11,Neutral,batch_11,Neutral,3,Neutral,OK
94,"The global anomaly branch adopts the method in [40], so the result is the same.",RS_104_MLRC_2020_11,First Author: Park,A3NAHN61XJ3ZAT,20,Neutral,A2R2YZTSME1K3F,28,Neutral,A2HM35CWB7IIFM,3,Positive,batch_16,Neutral,2,Positive,ISSUE
94,"Following the promising results of Split-model [23] trained on the publicly available ICDAR 2013 dataset using TabAug, we believe our work provides a strong foundation for numerous future extensions.",RS_138_ICDAR_2018_05,First Author: Tensmeyer,A18LFH7XW61JO9,8,Positive,A1FVXS8IM5QYO8,4,Positive,A2HM35CWB7IIFM,4,Positive,batch_26,Positive,3,Positive,OK
98,This finding is different from the vision domain in which computing the loss on unmasked image patches reduces accuracy [10].,RS_040_MLRC_2022_40,First Author: He,A5V3ZMQI0PU3F,27,Negative,A18LFH7XW61JO9,12,Neutral,A2R2YZTSME1K3F,35,Negative,batch_1,Negative,2,Negative,OK
99,"To produce a distribution over continuous actions instead of discrete tokens, C-BeT augments standard text generation transformers with the action discretization introduced in Behavior Transformers (BeT) (Shafiullah et al., 2022).",RS_043_MLRC_2022_43,"Cited Paper: (Shafiullah et al., 2022)",A2QD9PJUKW7PKK,76,Positive,A2HM35CWB7IIFM,4,Positive,A5V3ZMQI0PU3F,1885,Neutral,batch_6,Positive,2,Positive,OK
101,We follow the same settings as in [44] to create spurious correlation.,RS_063_MLRC_2021_18,First Author: Mahajan,A3NAHN61XJ3ZAT,12,Positive,A18LFH7XW61JO9,16,Neutral,A2QD9PJUKW7PKK,668,Positive,batch_9,Positive,2,Positive,OK
108,Sauer-Geiger [17] proposed the generative model to create counterfactual images where the texture in the foreground and background of an object are independently altered to that of other classes in ImageNet.,RS_047_MLRC_2021_02,First Author: Sauer,A2QD9PJUKW7PKK,43,Neutral,A1G94QON7A9K0N,51,Neutral,A2HM35CWB7IIFM,3,Positive,batch_7,Neutral,2,Neutral,OK
109,"Contrary to previous methods that claim that the stop-gradient, prediction head, and high predictor learning rate are enough to prevent the collapse [7,34], we show that collapse additionally depends on the model capacity relative to the data complexity.",RS_062_MLRC_2021_17,First Author: Tian,A3NAHN61XJ3ZAT,9,Neutral,A2QD9PJUKW7PKK,154,Negative,A18LFH7XW61JO9,15,Negative,batch_9,Negative,2,Negative,OK
120,"following baselines for performance comparison: (1) reasoning-focused methods: KV-Mem (Miller et al., 2016), GraftNet (Sun et al., 2018), EmbedKGQA (Saxena et al., 2020), NSM (He et al., 2021), TransferNet (Shi et al., 2021); (2) retrieval-augmented methods: PullNet (Sun et al., 2019), SR+NSM",RS_108_MLRC_2020_15,"Cited Paper: (Saxena et al., 2020)",A2R2YZTSME1K3F,57,Positive,A3NAHN61XJ3ZAT,13,Positive,A2HM35CWB7IIFM,4,Positive,batch_16,Positive,3,Positive,OK
122,"The original paper (Menon et al., 2020) uses  = 2 on CIFAR-10 and  = 10 on CIFAR-100, but the default setting does not work well in our experiments.",RS_106_MLRC_2020_13,"Cited Paper: (Menon et al., 2020)",A2R2YZTSME1K3F,199,Positive,A2HM35CWB7IIFM,8,Negative,A2QD9PJUKW7PKK,78,Negative,batch_16,Negative,2,Negative,OK
135,"[14] proposed a GAN2Shape model to recover 3-D shapes from a single RGB image in an unsupervised manner which mines only some 3-D geometric cues from 2-D images generated by generative adversarial network (GAN), and depth information of the RGB image cannot be provided.",RS_074_MLRC_2021_29,First Author: Pan,A3NAHN61XJ3ZAT,9,Neutral,A18LFH7XW61JO9,5,Neutral,A1G94QON7A9K0N,37,Negative,batch_10,Neutral,2,Neutral,OK
137,"For adversarial training, this paper uses the training scheme of AdvProp [10], which uses two separate batch normalization (BN) layers for clean and adversarial examples, arg     , ; , +    , ; , = arg + (7)",RS_124_NeurIPS_2019_07,First Author: Micaelli,A5V3ZMQI0PU3F,76,Positive,A2HM35CWB7IIFM,5,Positive,A2R2YZTSME1K3F,25,Neutral,batch_22,Positive,2,Positive,OK
145,"More recently [5] proposed EmbedKGQA, a framework with two training (i) train the knowledge graph embedding on the link prediction task; (ii) train the model for QA by leveraging the pretrained embeddings.",RS_108_MLRC_2020_15,First Author: Saxena,A3NAHN61XJ3ZAT,15,Neutral,A2R2YZTSME1K3F,43,Neutral,A18LFH7XW61JO9,128,Neutral,batch_16,Neutral,3,Neutral,OK
148,"To further enhance its distinguishing power for diverse scenarios on different roads over time, we sparsify the attention-based query mechanism (defined in Equation (7)) with two constraints [53, 54], including a consistency loss L1 and a contrastive loss L2, denoted by:",RS_104_MLRC_2020_11,First Author: Park,A2R2YZTSME1K3F,48,Positive,A3NAHN61XJ3ZAT,8,Neutral,A2HM35CWB7IIFM,4,Positive,batch_16,Positive,2,Positive,OK
154,"Successful retraining strategies such as weight and learning rate (LR) rewinding (Renda et al., 2020) both do this while finetuning (FT), an unsuccessful retraining strategy, does not.",RS_075_MLRC_2021_30,"Cited Paper: (Renda et al., 2020)",A3NAHN61XJ3ZAT,9,Neutral,A18LFH7XW61JO9,8,Negative,A2QD9PJUKW7PKK,74,Negative,batch_10,Negative,2,Neutral,ISSUE
161,"To do so, we first follow the denoising score-matching (DSM) process of a standard diffusion probabilistic model [36, 52].",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,11,Positive,A2HM35CWB7IIFM,4,Positive,A3NAHN61XJ3ZAT,10,Neutral,batch_18,Positive,2,Positive,OK
163,"Additionally, [7] extends this work proposing a generic form of the contrastive loss, also identifying the same relations of uniformity to pairwise potential in a Gaussian kernel, tomatch representations to a prior distribution (of high entropy).",RS_006_MLRC_2022_06,First Author: Chen,A18LFH7XW61JO9,72,Neutral,A2R2YZTSME1K3F,34,Neutral,A1NF6PELRKACS9,60,Positive,batch_1,Neutral,2,Neutral,OK
181,"[50], wherein data was collected by a purely random policy, which may well fail to explore many relevant regions of the games.",RS_126_NeurIPS_2019_09,First Author: Anand,A2HM35CWB7IIFM,5,Negative,A18LFH7XW61JO9,10,Neutral,AKSJ3C5O3V9RB,39113,Negative,batch_23,Negative,2,Negative,OK
197,"Following a mainstream convention in many sparse training papers (Frankle & Carbin, 2019; Gale et al., 2019; Evci et al., 2020; Lee et al., 2019; Liu et al., 2021c), we sparsify most layers in the model including embedding layers and classifier heads, and we do not apply advanced techniques such as",RS_114_MLRC_2020_21,First Author: Evci,A3NAHN61XJ3ZAT,6,Neutral,A2R2YZTSME1K3F,40,Positive,A2HM35CWB7IIFM,4,Positive,batch_17,Positive,2,Positive,OK
202,18We do not show LeAR results for SCAN and GeoQuery as Liu et al. (2021) did not report results for SCAN and reported GeoQuery results using a different template split and a different evaluation metric.,RS_044_MLRC_2022_44,First Author: Shaw,A2QD9PJUKW7PKK,107,Negative,A3NAHN61XJ3ZAT,12,Negative,A2HM35CWB7IIFM,7,Negative,batch_6,Negative,3,Negative,OK
204,"Our code is adapted from (Tian et al., 2021) 5, and we follow the same data augmentation process.",RS_062_MLRC_2021_17,"Cited Paper: (Tian et al., 2021)",A2QD9PJUKW7PKK,99,Positive,A3NAHN61XJ3ZAT,9,Positive,A18LFH7XW61JO9,6,Positive,batch_9,Positive,3,Positive,OK
205,"While these methods can achieve superior theoretical compression rates (Renda et al., 2020), their use remains impractical without specialised hardware that can take advantage of sparsity (Han et al.",RS_075_MLRC_2021_30,"Cited Paper: (Renda et al., 2020)",A3NAHN61XJ3ZAT,13,Negative,A18LFH7XW61JO9,6,Neutral,A1G94QON7A9K0N,69,Negative,batch_10,Negative,2,Negative,OK
205,"contrary to this common belief on text-guidance, the standard method (Patashnik et al., 2021) for text-based StyleGAN manipulation surprisingly fails to even find the manipulation directions that are known to be found in unsupervised approaches (Hrknen et al., 2020; Shen & Zhou, 2021) (see Fig.",RS_055_MLRC_2021_10,First Author: Härkönen,A18LFH7XW61JO9,7,Neutral,A2HM35CWB7IIFM,5,Negative,A1G94QON7A9K0N,21,Negative,batch_8,Negative,2,Negative,OK
208,"The models usually fail to distinguish textual similarity and semantic similarity, which has been discussed deeply in the vision field (Robinson et al., 2021; Chen et al., 2021).",RS_006_MLRC_2022_06,First Author: Chen,A5V3ZMQI0PU3F,25,Neutral,A18LFH7XW61JO9,13,Neutral,AKSJ3C5O3V9RB,100,Negative,batch_1,Neutral,2,Neutral,OK
211,"We evaluate our approach using four datasets: (i) Mini-ImageNet (Vinyals et al., 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al., 2018), (iv) and EMNIST (balanced) (Cohen et al., 2017).",RS_130_ICLR_2019_02,"Cited Paper: (Bertinetto et al., 2019)",A2R2YZTSME1K3F,176,Positive,A18LFH7XW61JO9,12,Positive,A1G94QON7A9K0N,9,Positive,batch_24,Positive,3,Positive,OK
214,"Comparison with NQG We cannot compare using CSL for data augmentation directly with using its closely related predecessor NQG (Shaw et al., 2021) for data augmentation, as NQG is a discriminative parsing model and not a probabilistic generative model that enables sampling new examples.",RS_044_MLRC_2022_44,"Cited Paper: (Shaw et al., 2021)",A3NAHN61XJ3ZAT,17,Negative,A1G94QON7A9K0N,29,Negative,AJ0RL2YCXZC25,37,Neutral,batch_6,Negative,2,Negative,OK
215,", using the vanilla dot production) used in prior arts [26, 46] is not adapted to fit the FSC task.",RS_084_MLRC_2021_39,First Author: Ranjan,A2QD9PJUKW7PKK,120,Negative,A3NAHN61XJ3ZAT,23,Negative,A1G94QON7A9K0N,22,Negative,batch_11,Negative,3,Negative,OK
222,"Note that EPAP-Netv0 is our baseline, MNAD-P w/o Mem [30].",RS_104_MLRC_2020_11,First Author: Park,A3NAHN61XJ3ZAT,6,Neutral,A2R2YZTSME1K3F,120,Positive,A18LFH7XW61JO9,9,Neutral,batch_16,Neutral,2,Neutral,OK
227,"named Scalable Representation Learning [12] is not included in our results, as it requires a much longer running time and we failed to produce its results in several days.",RS_121_NeurIPS_2019_04,First Author: Franceschi,A18LFH7XW61JO9,5,Neutral,A2R2YZTSME1K3F,158,Negative,A2QD9PJUKW7PKK,63,Negative,batch_21,Negative,2,Negative,OK
229,Dirichlet distribution is not used to approximate teachers predictive distribution for classification as in [32] because we empirically found it very numerically unstable and led to failure of convergence.,RS_103_MLRC_2020_10,First Author: Malinin,A3NAHN61XJ3ZAT,9,Negative,AJ0RL2YCXZC25,51,Neutral,A2HM35CWB7IIFM,7,Negative,batch_15,Negative,2,Negative,OK
231,"We benchmark against PECNet [77], a strong scene agnostic trajectory prediction method with state-of-the-art performance on standard intention agnostic prediction datasets.",RS_082_MLRC_2021_37,First Author: Mangalam,A3NAHN61XJ3ZAT,10,Neutral,A2QD9PJUKW7PKK,71,Positive,A2HM35CWB7IIFM,5,Positive,batch_11,Positive,2,Positive,OK
232,"Following the popular evaluation settings in the video anomaly detection community [8, 11, 17, 27, 32, 36], we report the area under the receiver operating characteristics curve (AUC) to evaluate the performance of the proposed framework.",RS_104_MLRC_2020_11,First Author: Park,A3NAHN61XJ3ZAT,14,Positive,A2R2YZTSME1K3F,47,Positive,A18LFH7XW61JO9,10,Positive,batch_16,Positive,3,Positive,OK
236,"While these models fail in Length splits for both SCAN and Okapi datasets, several models with specialized architectures [19, 26] have been proposed for SCAN dataset which achieve 100% accuracy on Length and MCD splits.",RS_044_MLRC_2022_44,First Author: Shaw,A2HM35CWB7IIFM,4,Positive,A3NAHN61XJ3ZAT,7,Neutral,A37WXDYYT7RCZ0,13,Neutral,batch_6,Neutral,2,Neutral,OK
237,"The theoretical analysis on self-supervised representation algorithms without negative samples [Tian et al., 2021] cannot be applied to the contrastive learning setting.",RS_062_MLRC_2021_17,First Author: Tian,A3NAHN61XJ3ZAT,13,Negative,A18LFH7XW61JO9,13,Neutral,A1G94QON7A9K0N,14,Negative,batch_9,Negative,2,Negative,OK
239,[32] enhanced this method by adding an additional identical matrix before multiplication to simulate the effect of residual connection of MSA.,RS_049_MLRC_2021_04,First Author: Chefer,A2QD9PJUKW7PKK,79,Neutral,A1FVXS8IM5QYO8,4,Positive,A2HM35CWB7IIFM,4,Positive,batch_7,Positive,2,Positive,OK
244,", 2019] and Match-DG [Mahajan et al., 2020], while Deep-All is used as baseline by pooling all training domains together.",RS_063_MLRC_2021_18,First Author: Mahajan,A3NAHN61XJ3ZAT,13,Neutral,A2R2YZTSME1K3F,88,Positive,A5V3ZMQI0PU3F,25,Neutral,batch_9,Neutral,2,Neutral,OK
245,In our work we use global pruning as used in the paper we are reproducing [4].,RS_127_NeurIPS_2019_10,First Author: Morcos,A2R2YZTSME1K3F,52,Positive,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,13,Neutral,batch_24,Positive,2,Positive,OK
247,To evaluate the quality of the learned representations we proposed and utilised novel extensions to an evaluation method that probes the representations using the AtariARI [5].,RS_126_NeurIPS_2019_09,First Author: Anand,A18LFH7XW61JO9,10,Positive,A2HM35CWB7IIFM,4,Positive,A2R2YZTSME1K3F,107,Positive,batch_23,Positive,3,Positive,OK
249,"In this experiment, we use FixMatch [33] as the baseline for semi supervised learning and follow the same configuration for training.",RS_102_MLRC_2020_09,First Author: Sohn,A1G94QON7A9K0N,17,Positive,A3NAHN61XJ3ZAT,7,Positive,A2QD9PJUKW7PKK,90,Positive,batch_12,Positive,3,Positive,OK
257,"S1), we used a diverse set of training dataset and employed the Masked Autoencoders (MAE) method [He et al., 2022] as the Pre-training method.",RS_040_MLRC_2022_40,First Author: He,A18LFH7XW61JO9,48,Positive,A5V3ZMQI0PU3F,21,Positive,A2R2YZTSME1K3F,34,Positive,batch_1,Positive,3,Positive,OK
263,"Despite of the good performance, such large models are not applicable when memory or computational resources are limited (Bellec et al., 2017; Evci et al., 2020; Liu et al., 2022).",RS_114_MLRC_2020_21,First Author: Evci,A3NAHN61XJ3ZAT,16,Negative,A2HM35CWB7IIFM,5,Negative,A2R2YZTSME1K3F,344,Neutral,batch_17,Negative,2,Negative,OK
269,"Following previous works [25, 27, 62], we evaluate our proposed methods on three standard OOD generalisation benchmark datasets described below.",RS_063_MLRC_2021_18,First Author: Mahajan,A18LFH7XW61JO9,13,Positive,A3NAHN61XJ3ZAT,14,Positive,A2QD9PJUKW7PKK,68,Positive,batch_9,Positive,3,Positive,OK
272,"The states dynamics of Hamiltonian systems can be written as [2, 13]",RS_123_NeurIPS_2019_06,First Author: Greydanus,A18LFH7XW61JO9,5,Neutral,A2R2YZTSME1K3F,37,Neutral,A5V3ZMQI0PU3F,40,Neutral,batch_21,Neutral,3,Neutral,OK
292,"Note that prior works that manipulate one feature at a time in latent space [1, 9, 31, 36, 40, 43] are not applicable in our context.",RS_055_MLRC_2021_10,First Author: Härkönen,A1G94QON7A9K0N,27,Negative,A18LFH7XW61JO9,9,Neutral,AKSJ3C5O3V9RB,11669,Negative,batch_8,Negative,2,Neutral,ISSUE
300,"In fact, although model-based methods are data-efficient, they suffer from the compounding prediction error increasing with model rollout length, which greatly affects the performance and limits model rollout length [Janner et al., 2019].",RS_125_NeurIPS_2019_08,First Author: Janner,A2R2YZTSME1K3F,68,Neutral,A2HM35CWB7IIFM,3,Negative,A1G94QON7A9K0N,17,Negative,batch_22,Negative,2,Negative,OK
305,We visualize the attention maps of transformers using Transformer Explainability [6].,RS_049_MLRC_2021_04,First Author: Chefer,A2QD9PJUKW7PKK,52,Positive,A1G94QON7A9K0N,15,Positive,A18LFH7XW61JO9,21,Neutral,batch_7,Positive,2,Positive,OK
309,"Also, [23, 26] used different train/test split from the original competition without publishing their split and so cannot be compared directly.",RS_134_ICDAR_2018_01,First Author: Schreiber,A2R2YZTSME1K3F,57,Neutral,A5V3ZMQI0PU3F,89,Negative,A2HM35CWB7IIFM,3,Negative,batch_25,Negative,2,Negative,OK
315,"Using existing latent space manipulation techniques, 2D GANs [7,10,21] can produce stylized images from multiple camera poses.",RS_055_MLRC_2021_10,First Author: Härkönen,A2QD9PJUKW7PKK,45,Neutral,A1G94QON7A9K0N,51,Positive,A3NAHN61XJ3ZAT,9,Neutral,batch_8,Neutral,2,Neutral,OK
330,"typically either taken from different locations of the data [e.g., spatial patches or temporal locations, see Hjelm et al., 2018, Oord et al., 2018, Anand et al., 2019, Hnaff et al., 2019] or obtained through data augmentation [Wu et al., 2018, He et al., 2019, Bachman et al., 2019, Tian et",RS_126_NeurIPS_2019_09,First Author: Anand,A18LFH7XW61JO9,8,Neutral,A2R2YZTSME1K3F,32,Neutral,A2QD9PJUKW7PKK,52,Neutral,batch_23,Neutral,3,Neutral,OK
333,"If L corresponds to a Markov process corresponding to a continuous version of simulated tempering, we show the corresponding generalized score matching loss is a Gaussian-convolution annealed score matching loss, akin to the one proposed in Song and Ermon (2019).",RS_120_NeurIPS_2019_03,First Author: Song,A37WXDYYT7RCZ0,8,Positive,A18LFH7XW61JO9,17,Neutral,A2HM35CWB7IIFM,3,Positive,batch_18,Positive,2,Positive,OK
335,We test our method on the following four physical systems from [11]:,RS_123_NeurIPS_2019_06,First Author: Greydanus,A18LFH7XW61JO9,16,Positive,A2R2YZTSME1K3F,73,Positive,A2HM35CWB7IIFM,4,Positive,batch_21,Positive,3,Positive,OK
340,"Altogether, our weak supervision outperforms the state-of-the-art with image-based input (Schreiber et al., 2018) by a considerable margin.",RS_134_ICDAR_2018_01,"Cited Paper: (Schreiber et al., 2018)",A2HM35CWB7IIFM,4,Positive,A2QD9PJUKW7PKK,77,Positive,A2R2YZTSME1K3F,115,Positive,batch_25,Positive,3,Positive,OK
349,"The dataset comes without predefined train/test split; hence, we follow Schreiber et al. (2018) and split the so-called competition part of the dataset with a 50%/50%-ratio.",RS_134_ICDAR_2018_01,First Author: Schreiber,A18LFH7XW61JO9,8,Neutral,A2HM35CWB7IIFM,3,Positive,A1G94QON7A9K0N,9,Positive,batch_26,Positive,2,Positive,OK
361,We reimplemented the DeepDeSRT table structure model [6] and trained it on the same private data as our proposed model.,RS_134_ICDAR_2018_01,First Author: Schreiber,A18LFH7XW61JO9,8,Neutral,A2HM35CWB7IIFM,4,Positive,A1G94QON7A9K0N,8,Positive,batch_26,Positive,2,Positive,OK
362,"Their proposed solutions for GNN explanations are too straightforward, making it hard to achieve significant results on other datasets, such as the ones in [7, 8].",RS_100_MLRC_2020_07,First Author: Luo,A3NAHN61XJ3ZAT,12,Negative,A1G94QON7A9K0N,20,Negative,A2QD9PJUKW7PKK,73,Negative,batch_12,Negative,3,Negative,OK
363,"However, we were unable to obtain reasonable performance, even after exploring a variety of values for post processing thresholds and training hyperparameters (values not specified in [6]).",RS_134_ICDAR_2018_01,First Author: Schreiber,A18LFH7XW61JO9,10,Negative,A1G94QON7A9K0N,10,Negative,A2HM35CWB7IIFM,4,Negative,batch_26,Negative,3,Negative,OK
372,"Therefore, we follow [7, 8] to formulate structural explanations as binary classification tasks, wherein influential nodes and edges of predictions are included in explanations.",RS_100_MLRC_2020_07,First Author: Luo,A3NAHN61XJ3ZAT,5,Neutral,A2HM35CWB7IIFM,4,Positive,A1G94QON7A9K0N,9,Positive,batch_12,Positive,2,Positive,OK
382,"uncertainty estimates, e.g., gender and age groups.et al. (2020) report 1.7% ECE with Rank-1 Bayesian neural nets and 3.0% with Deep Ensembles; Thulasidasan et al. (2019a) report 3.2% for ResNet-50 with Mixup, 2.9% for ResNet-50 with an entropy-regularized loss, and 1.8% for ResNet-50 with",RS_128_NeurIPS_2019_11,First Author: Thulasidasan,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,15,Neutral,A2R2YZTSME1K3F,82,Neutral,batch_24,Neutral,2,Neutral,OK
392,"hnique has also been used in semi-supervised learning (Berthelot et al. 2019) and also used to improve the robustness (Li, Socher, and Hoi 2020), uncertainty (Hendrycks et al. 2019), and calibration (Thulasidasan et al. 2019) of DNN classiers. Our Framework From KD to L2RKD Hinton et al. (Hinton, Vinyals, and Dean 2015) propose KD which minimizes the output probability differences between a student and a teacher over dat",RS_128_NeurIPS_2019_11,Cited Paper: (Thulasidasan et al. 2019),A18LFH7XW61JO9,13,Positive,A1G94QON7A9K0N,25,Neutral,A2QD9PJUKW7PKK,212,Neutral,batch_24,Neutral,2,Neutral,OK
421,"Abstract In this study, we performed some ablations on the main model developed in the paper ""Unsupervised Representation Learning in Atari"" [2] as part of the 2019 NeurIPS Reproducibility Challenge.",RS_126_NeurIPS_2019_09,First Author: Anand,A18LFH7XW61JO9,12,Neutral,A1G94QON7A9K0N,8,Positive,A2QD9PJUKW7PKK,226,Positive,batch_24,Positive,2,Positive,OK
428,"Although Luo et al. (2016) propose to measure the ERF for CNNs, it cannot be directly implemented to Transformer-base models.",RS_049_MLRC_2021_04,First Author: Chefer,A2HM35CWB7IIFM,3,Negative,A1G94QON7A9K0N,13,Negative,A2QD9PJUKW7PKK,127,Neutral,batch_7,Negative,2,Negative,OK
428,"Another recent work (Franceschi et al., 2019) makes use of convolutional neural networks in a framework heavily inspired by word2vec (Mikolov et al.",RS_121_NeurIPS_2019_04,"Cited Paper: (Franceschi et al., 2019)",A2QD9PJUKW7PKK,44,Negative,A2R2YZTSME1K3F,63,Neutral,A1G94QON7A9K0N,8,Neutral,batch_21,Neutral,2,Neutral,OK
433,"In sparse masks, the number of incoming/outgoing connections is not identical for all the neurons in the layer (Evci et al., 2020b) and this raises direct concerns against the blind usage of dense network initialization for sparse subnetworks.",RS_114_MLRC_2020_21,First Author: Evci,A3NAHN61XJ3ZAT,41,Negative,A2R2YZTSME1K3F,39,Neutral,A3EG4C9T4F5DUR,1549,Negative,batch_17,Negative,2,Negative,OK
438,"Assume we have a bootstrapped dynamics ensemble model f consisting of K different models (f1, . . . , fK) trained with different sequences of mini-batches of D (Chua et al., 2018; Janner et al., 2019).",RS_125_NeurIPS_2019_08,First Author: Janner,A2R2YZTSME1K3F,50,Positive,A1G94QON7A9K0N,8,Positive,A5V3ZMQI0PU3F,44,Neutral,batch_22,Positive,2,Positive,OK
448,"In [10], the authors analyze previous methods and their capability to generalize well for longer time horizons.",RS_125_NeurIPS_2019_08,First Author: Janner,A1G94QON7A9K0N,26,Neutral,A2R2YZTSME1K3F,32,Neutral,A3EG4C9T4F5DUR,5854,Positive,batch_22,Neutral,2,Neutral,OK
451,"Due to weight sharing in convolutional layers, ERK sparsity distribution doubles the FLOPs required at a given sparsity (Evci et al., 2020), which we also found to be the case with the convolutional networks used by DQN in the Atari environments (see subsection A.2 for further discussion).",RS_114_MLRC_2020_21,"Cited Paper: (Evci et al., 2020)",A3NAHN61XJ3ZAT,17,Neutral,A2R2YZTSME1K3F,72,Neutral,A2HM35CWB7IIFM,11,Positive,batch_17,Neutral,2,Positive,ISSUE
461,"But fine-grained testing does not work well when comparing mixup methods and non-mixup methods, since mixup is better class-calibrated [41].",RS_128_NeurIPS_2019_11,First Author: Thulasidasan,A2HM35CWB7IIFM,4,Negative,AKSJ3C5O3V9RB,4671,Negative,A18LFH7XW61JO9,14,Neutral,batch_24,Negative,2,Negative,OK
464,"While it somewhat outperforms the rollout method in specific scenarios, it is not ready to support large-scale evaluations [15].",RS_049_MLRC_2021_04,First Author: Chefer,A18LFH7XW61JO9,16,Negative,A1G94QON7A9K0N,10,Negative,A2HM35CWB7IIFM,4,Negative,batch_7,Negative,3,Negative,OK
475,Trying to teach computers to see and alsounderstand what is a table has proven be extremely difficult [25].,RS_134_ICDAR_2018_01,First Author: Schreiber,A18LFH7XW61JO9,12,Neutral,A2HM35CWB7IIFM,3,Negative,A1G94QON7A9K0N,12,Neutral,batch_26,Neutral,2,Neutral,OK
489,"To ver-ify the effectiveness of Sup-tickets, we apply it to various sparse training methods, including 3 DST methods: SET, RigL [Evci et al., 2020], and GraNet [Liu et al., 2021b]; one SST method: ERK [Evci et al., 2020]; and one pruning at initialization approach: SNIP [Lee et al., 2018].",RS_114_MLRC_2020_21,First Author: Evci,A3NAHN61XJ3ZAT,14,Positive,A2R2YZTSME1K3F,32,Positive,A3EG4C9T4F5DUR,50,Positive,batch_17,Positive,3,Positive,OK
521,"for random pruning, every layer can be uniformly pruned with the same pre-defined pruning ratio (Mariet and Sra, 2015; He et al., 2017; Gale et al., 2019) or the pruning ratio can be varied for different layers such as Erdo-Renyi (Mocanu et al., 2018) and Erdo-Renyi Kernel (Evci et al., 2020).",RS_114_MLRC_2020_21,"Cited Paper: (Evci et al., 2020)",A3NAHN61XJ3ZAT,9,Neutral,A2R2YZTSME1K3F,38,Neutral,A3EG4C9T4F5DUR,13,Positive,batch_17,Neutral,2,Neutral,OK
522,"Consistent with prior works [11, 14, 34], we focus on explanations on graph structures.",RS_100_MLRC_2020_07,First Author: Luo,A3NAHN61XJ3ZAT,7,Neutral,A1G94QON7A9K0N,16,Positive,A2HM35CWB7IIFM,3,Positive,batch_12,Positive,2,Neutral,ISSUE
531,"Motivated by such an analysis, they proposed the AutoMBPO framework to automatically schedule the key hyperparameters of the MBPO [Janner et al., 2019] algorithm.",RS_125_NeurIPS_2019_08,First Author: Janner,A2R2YZTSME1K3F,146,Neutral,A1G94QON7A9K0N,7,Neutral,A5V3ZMQI0PU3F,48,Neutral,batch_22,Neutral,3,Neutral,OK
533,"[24] requires explicit motif to generate explanations thus could not be applied on NCI1 and CiteSeer, which is the reason why it is not included.",RS_100_MLRC_2020_07,First Author: Luo,A3NAHN61XJ3ZAT,7,Negative,A2QD9PJUKW7PKK,234,Neutral,A1G94QON7A9K0N,12,Negative,batch_12,Negative,2,Negative,OK
554,"Following (Greydanus et al., 2019), we evaluate the MSEs of the predicted trajectories and energies from their corresponding ground truth at each time step.",RS_123_NeurIPS_2019_06,"Cited Paper: (Greydanus et al., 2019)",A2R2YZTSME1K3F,36,Positive,A1G94QON7A9K0N,9,Positive,A18LFH7XW61JO9,8,Positive,batch_21,Positive,3,Positive,OK
559,"In this paper, we focus on theories of the properties of the most fundamental model, comprising Hamiltonian neural networks (HNNs) (Greydanus, Dzamba, and Yosinski 2019)du dt = S HNN u(2)and their extensions in practical situations, where the learning error is not completely zero.",RS_123_NeurIPS_2019_06,First Author: Greydanus,A18LFH7XW61JO9,5,Neutral,A2HM35CWB7IIFM,3,Positive,A2R2YZTSME1K3F,121,Positive,batch_21,Positive,2,Positive,OK
568,"Thulasidasan et al. (2019) has demonstrated Mixups ability to distinguish ood samples however, we believe that natural shift is a weaker notion of data shift than ood evaluation and MX fails to provide any benefit in this regard.",RS_128_NeurIPS_2019_11,First Author: Thulasidasan,A18LFH7XW61JO9,21,Neutral,A2HM35CWB7IIFM,4,Negative,A1G94QON7A9K0N,14,Negative,batch_24,Negative,2,Negative,OK
577,"A prevalent solution is building an explainer model to conduct feature attribution (Ying et al., 2019; Luo et al., 2020; Pope et al., 2019).",RS_100_MLRC_2020_07,First Author: Luo,A3NAHN61XJ3ZAT,7,Neutral,A2QD9PJUKW7PKK,42,Neutral,A1G94QON7A9K0N,37,Neutral,batch_12,Neutral,3,Neutral,OK
589,"For a fair comparison we also include LRR (Renda et al., 2020) which uses a pre-trained network and multiple rounds of pruning and retraining by leveraging learning rate rewinding.",RS_075_MLRC_2021_30,"Cited Paper: (Renda et al., 2020)",A3NAHN61XJ3ZAT,15,Positive,A18LFH7XW61JO9,7,Positive,A1G94QON7A9K0N,16,Positive,batch_10,Positive,3,Positive,OK
620,"We also tried MBPO [35], but we found that this method takes too much memory and could not finish any test.",RS_125_NeurIPS_2019_08,First Author: Janner,A1G94QON7A9K0N,12,Negative,A2R2YZTSME1K3F,50,Negative,A2HM35CWB7IIFM,4,Negative,batch_22,Negative,3,Negative,OK
633,"[26], one of the state-of-the-art (SOTA) first-order optimizers, introduced a new second-order momentum using a squared error between the current gradient and the first-order momentum, which is formulated as",RS_054_MLRC_2021_09,First Author: Zhuang,A2QD9PJUKW7PKK,165,Neutral,A18LFH7XW61JO9,32,Neutral,A1G94QON7A9K0N,38,Neutral,batch_7,Neutral,3,Neutral,OK
663,"In our approach, we adopt the masked autoencoder [19] to improve the channel estimation performance.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,146,Positive,A1FVXS8IM5QYO8,6,Positive,A37WXDYYT7RCZ0,23,Neutral,batch_2,Positive,2,Positive,OK
669,"For example, as shall be shown, pairing StyleFusion with GANSpace [Hrknen et al. 2020] or StyleCLIP [Patashnik et al. 2021] leverages their diverse manipulations while ensuring that the resulting edits alter only the desired semantic regions.",RS_055_MLRC_2021_10,First Author: Härkönen,A2QD9PJUKW7PKK,136,Positive,A2HM35CWB7IIFM,4,Positive,A1G94QON7A9K0N,57,Positive,batch_8,Positive,3,Positive,OK
715,By physics-inspired neural networks [4] authors generally mean either incorporating domain knowledge in the traditional NN or providing additional loss functions to ensure physically consistent predictions [57].,RS_123_NeurIPS_2019_06,First Author: Greydanus,A5V3ZMQI0PU3F,92,Neutral,A2R2YZTSME1K3F,58,Neutral,A3EG4C9T4F5DUR,6425,Positive,batch_22,Neutral,2,Neutral,OK
737,", the dyna-style algorithm, which has recently shown the potential to achieve high sample efficiency (Janner et al. 2019).",RS_125_NeurIPS_2019_08,Cited Paper: (Janner et al. 2019),A18LFH7XW61JO9,10,Neutral,A37WXDYYT7RCZ0,5,Positive,A2QD9PJUKW7PKK,48,Positive,batch_23,Positive,2,Neutral,ISSUE
742,"However, many of these results are achieved by model-free algorithms and generally require a massive number of samples, which significantly hinders the applications of modelfree methods in real-world tasks (Kurutach et al. 2018; Janner et al. 2019).",RS_125_NeurIPS_2019_08,First Author: Janner,A2HM35CWB7IIFM,4,Negative,A3EG4C9T4F5DUR,4056,Negative,AKSJ3C5O3V9RB,23536,Negative,batch_23,Negative,3,Negative,OK
785,"Following Evci et al. (2019); Gale et al. (2019), we conduct experiments to compare this strong baseline with `1-norm filters pruning while employing CLR on CIFAR-10, CIFAR-100 and ImageNet.",RS_114_MLRC_2020_21,First Author: Evci,A3NAHN61XJ3ZAT,13,Positive,A2R2YZTSME1K3F,42,Positive,A3EG4C9T4F5DUR,1617,Positive,batch_17,Positive,3,Positive,OK
789,"Due to limited computation, we are unable to use large batch sizes as in FixMatch (Sohn et al., 2020) (1024 for labeled data and 5120 for unlabeled data).",RS_102_MLRC_2020_09,"Cited Paper: (Sohn et al., 2020)",A18LFH7XW61JO9,23,Negative,A2QD9PJUKW7PKK,70,Negative,A2HM35CWB7IIFM,5,Negative,batch_13,Negative,3,Negative,OK
790,We calculate theoretical FLOP requirements in a manner similar to Evci et al. [2020] (exact details in the supplementary material).,RS_114_MLRC_2020_21,First Author: Evci,A3NAHN61XJ3ZAT,21,Neutral,A1G94QON7A9K0N,17,Positive,A2R2YZTSME1K3F,70,Positive,batch_17,Positive,2,Positive,OK
793,"We conduct ablation studies to better understand our approach InPL, where we integrate it into the framework of FixMatch (Sohn et al., 2020) and ABC (Lee et al., 2021).",RS_102_MLRC_2020_09,"Cited Paper: (Sohn et al., 2020)",A18LFH7XW61JO9,36,Neutral,A2QD9PJUKW7PKK,150,Positive,A2HM35CWB7IIFM,5,Positive,batch_13,Positive,2,Positive,OK
803,"This paper focuses on the instance-level explanation, for which most of the existing methods, e.g., GNNExplainer (Ying et al., 2019), PGExplainer (Luo et al., 2020) and methods in Pope et al. (2019), only consider lower-order features, i.e., nodes and edges, ignoring higher-order interactions.",RS_100_MLRC_2020_07,"Cited Paper: (Luo et al., 2020)",A3NAHN61XJ3ZAT,9,Neutral,A1G94QON7A9K0N,14,Positive,A2QD9PJUKW7PKK,16950,Neutral,batch_12,Neutral,2,Neutral,OK
825,"As expected, MAE [37] struggles in these setups.",RS_040_MLRC_2022_40,First Author: He,A2HM35CWB7IIFM,4,Negative,A1FVXS8IM5QYO8,4,Negative,A18LFH7XW61JO9,12,Negative,batch_2,Negative,3,Negative,OK
847,"We compare RoPAWS with PAWS and FixMatch (Sohn et al., 2020), together with state-of-the-art robust Semi-SL (OOD filtering) methods: UASD (Chen et al., 2020d), DS3L (Guo et al., 2020), OpenMatch (Saito et al., 2021), and OpenCos (Park et al., 2021).",RS_102_MLRC_2020_09,"Cited Paper: (Sohn et al., 2020)",A18LFH7XW61JO9,11,Positive,A2HM35CWB7IIFM,5,Positive,A3NAHN61XJ3ZAT,9,Positive,batch_13,Positive,3,Positive,OK
855,", 2020) that follows MBPO (Janner et al., 2019) with additional reward penalties and MBOP (Argenson and Dulac-Arnold, 2020) that learns an offline model to perform online planning.",RS_125_NeurIPS_2019_08,"Cited Paper: (Janner et al., 2019)",A18LFH7XW61JO9,10,Positive,A2QD9PJUKW7PKK,76,Neutral,A2R2YZTSME1K3F,19,Neutral,batch_23,Neutral,2,Neutral,OK
856,"MOPO (Yu et al., 2020) follows MBPO Janner et al. (2019) with additional reward penalty on unreliable model-generated transitions.",RS_125_NeurIPS_2019_08,First Author: Janner,A18LFH7XW61JO9,14,Positive,A2R2YZTSME1K3F,65,Neutral,A2QD9PJUKW7PKK,40,Neutral,batch_23,Neutral,2,Neutral,OK
914,"More specifically, for a given method that discovers a set of paths, that is, linear in the cases of [34, 11] or non-linear in our case, in the latent space of a pretrained GAN, we generate an image sequence for each path, starting from a random latent code and walking towards the positive and the negative ways of the path for a certain amount of steps.",RS_055_MLRC_2021_10,First Author: Härkönen,A1G94QON7A9K0N,32,Positive,A18LFH7XW61JO9,7,Neutral,A2HM35CWB7IIFM,4,Positive,batch_8,Positive,2,Positive,OK
952,"In our method, each training trajectory has an overlap much larger than (Janner et al., 2019) has with the expert trajectory.",RS_125_NeurIPS_2019_08,"Cited Paper: (Janner et al., 2019)",A18LFH7XW61JO9,13,Neutral,A2R2YZTSME1K3F,58,Positive,A2HM35CWB7IIFM,7,Positive,batch_23,Positive,2,Positive,OK
1008,"As claimed in MAE [49], auto-encoder models may be comparative with contrastive models, so VGNAE tries to explore auto-encoder mechanism further and achieve the best performance on some tasks.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,81,Positive,A3NAHN61XJ3ZAT,86,Positive,A18LFH7XW61JO9,13,Neutral,batch_2,Positive,2,Positive,OK
1010,"We compare with global magnitude (GM) following the same schedule as oViT, as well as the state-of-the-art SViTE [Chen et al., 2021] paper, which trains the sparse model from scratch using a variant of RigL [Evci et al., 2020], but for a total of 600 epochs.",RS_114_MLRC_2020_21,First Author: Evci,A37WXDYYT7RCZ0,9,Positive,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,10,Positive,batch_18,Positive,3,Positive,OK
1024,"(2)This process is done by a base learner (machine learning algorithm) in some meta learning methods (Bertinetto et al., 2019; Lee et al., 2019).",RS_130_ICLR_2019_02,First Author: Bertinetto,A2HM35CWB7IIFM,3,Neutral,A2R2YZTSME1K3F,134,Neutral,A2QD9PJUKW7PKK,33,Neutral,batch_25,Neutral,3,Neutral,OK
1025,"The formulation of few-shot learning we use here is similar to Lee et al. (2019); Bertinetto et al. (2019), but also other formulations of few shot learning exist, e.g., MAML (Finn et al., 2017).",RS_130_ICLR_2019_02,First Author: Bertinetto,A2HM35CWB7IIFM,4,Positive,A2R2YZTSME1K3F,73,Positive,A5V3ZMQI0PU3F,68,Positive,batch_25,Positive,3,Positive,OK
1026,", 2022); (3) Language has a higher information density compared to images (He et al., 2022) and tables, the transformation from low-density to high-density can be done losslessly for tables and with minimal loss for images using",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A2QD9PJUKW7PKK,818,Neutral,A18LFH7XW61JO9,10,Neutral,AKSJ3C5O3V9RB,31973,Positive,batch_2,Neutral,2,Neutral,OK
1041,"On the other hand, LTH-based (Chen et al., 2020a; Evci et al., 2020) methods can be borrowed to find the mask by several iterations, but it is prohibitively time-consuming.",RS_114_MLRC_2020_21,First Author: Evci,A18LFH7XW61JO9,11,Neutral,AKSJ3C5O3V9RB,289,Negative,A3NAHN61XJ3ZAT,6,Neutral,batch_18,Neutral,2,Neutral,OK
1043,"Recently, masked autoencoder (MAE) [23] has exhibited great success on various computer vision",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,141,Neutral,A18LFH7XW61JO9,19,Neutral,A37WXDYYT7RCZ0,28,Neutral,batch_2,Neutral,3,Neutral,OK
1059,Layerwise manipulation of the GANs are then performed to produce edits in the input image that are interpretable in terms of chosen semantic features [16].,RS_055_MLRC_2021_10,First Author: Härkönen,A1G94QON7A9K0N,31,Positive,A2HM35CWB7IIFM,5,Positive,A2QD9PJUKW7PKK,14866,Neutral,batch_8,Positive,2,Positive,OK
1103,"As observed in other studies [5, 33], AEs tend to generalize too well to out-of-distribution data.",RS_040_MLRC_2022_40,First Author: He,AH3ER3EJXHRO2,9,Negative,A2HM35CWB7IIFM,4,Negative,A2QD9PJUKW7PKK,92,Neutral,batch_2,Negative,2,Neutral,ISSUE
1119,"However, this protocol is not suitable for the evaluation of non-linear representations [1, 11, 15].",RS_040_MLRC_2022_40,First Author: He,A2HM35CWB7IIFM,8,Negative,A2QD9PJUKW7PKK,128,Neutral,A1FVXS8IM5QYO8,6,Negative,batch_2,Negative,2,Negative,OK
1123,"We attempt to interpret the latent space of the model trained to synthesize all classes (setting B), following [13].",RS_055_MLRC_2021_10,First Author: Härkönen,A1G94QON7A9K0N,24,Positive,A2QD9PJUKW7PKK,86,Positive,A2HM35CWB7IIFM,4,Positive,batch_8,Positive,3,Positive,OK
1227,"Additionally, to visualize the procedure of cyclic update, we choose a test scenario where the ground truth classes of five query images are [1, 2, 3, 4, 5] and visualize instance-level similarities which is used for predictions of five query samples as shown in Figure 8.",RS_130_ICLR_2019_02,First Author: Bertinetto,A2HM35CWB7IIFM,4,Positive,A2QD9PJUKW7PKK,40,Neutral,A2R2YZTSME1K3F,95,Positive,batch_25,Positive,2,Positive,OK
1268,"We introduce a practical and efficient algorithm for TASML, along with several algorithmic modifications aimed at improving model efficiency and performance, including: representation pre-training, optimization as a layer Amos & Kolter (2017); Bertinetto et al. (2019), and least-squares relaxation of classification loss.",RS_130_ICLR_2019_02,First Author: Bertinetto,A2HM35CWB7IIFM,5,Positive,A2QD9PJUKW7PKK,45,Neutral,A2R2YZTSME1K3F,57,Positive,batch_25,Positive,2,Positive,OK
1273,"3 we compare NARL against the publicly released data from [34], setting (M = 3, M = 1) and (M = 5, M = 0.",RS_125_NeurIPS_2019_08,First Author: Janner,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,13,Positive,A2R2YZTSME1K3F,51,Positive,batch_23,Positive,3,Positive,OK
1304,"Our study utilizes two well-performing self-supervised Vision Transformers, MAE (He et al., 2022) and MoCo v3 (Chen et al.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A2HM35CWB7IIFM,3,Positive,A2QD9PJUKW7PKK,147,Positive,A1FVXS8IM5QYO8,6,Positive,batch_2,Positive,3,Positive,OK
1306,"To simplify the consistency regularization process, FixMatch (Sohn et al., 2020) classified two unlabeled augmented views into a weak view and a strong view, and then minimized the divergence between the probability dis-",RS_102_MLRC_2020_09,"Cited Paper: (Sohn et al., 2020)",A18LFH7XW61JO9,13,Neutral,A2QD9PJUKW7PKK,69,Positive,A3NAHN61XJ3ZAT,7,Neutral,batch_13,Neutral,2,Neutral,OK
1329,"The latent space can also be used as a way to control the generation process, for instance to edit images [15, 16, 17].",RS_055_MLRC_2021_10,First Author: Härkönen,A2HM35CWB7IIFM,4,Positive,A1G94QON7A9K0N,49,Neutral,A1IXVXZ5AYYNMJ,8,Neutral,batch_8,Neutral,2,Neutral,OK
1334,"Despite there are many methods aiming to find out these relations [8,15], most of them are too costly to be a practical option.",RS_055_MLRC_2021_10,First Author: Härkönen,A1G94QON7A9K0N,18,Negative,A3NAHN61XJ3ZAT,13,Negative,A2HM35CWB7IIFM,3,Negative,batch_8,Negative,3,Negative,OK
1350,"Interestingly MAE achieves high linear-classification accuracy but performs very poorly on kNN evaluation protocols [40], perhaps also indicating a lack of clustering based on class-specific semantic information.",RS_040_MLRC_2022_40,First Author: He,A18LFH7XW61JO9,36,Neutral,A2QD9PJUKW7PKK,65,Negative,A37WXDYYT7RCZ0,7,Neutral,batch_2,Neutral,2,Neutral,OK
1398,"Then, we apply a sharpening function to reduce the entropy of the label distribution instead of a argmax function used in [29] since some potential associations between different class embeddings are covered.",RS_102_MLRC_2020_09,First Author: Sohn,A2QD9PJUKW7PKK,64,Positive,A2HM35CWB7IIFM,5,Positive,A18LFH7XW61JO9,13,Neutral,batch_13,Positive,2,Positive,OK
1506,"Towards this goal, we leverage the denoising score-matching generative model [58] to model the gradient of its log-probability.",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,22,Neutral,A2R2YZTSME1K3F,33,Positive,A2HM35CWB7IIFM,4,Positive,batch_19,Positive,2,Positive,OK
1511,"As suggested by [13], we use a masking ratio of 75%, which speeds up the pretraining process since only 25% of the patches need to be processed by the MAE encoder.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,259,Positive,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,14,Positive,batch_2,Positive,3,Positive,OK
1527,"as a general-purpose tool for learning complex policies (Mnih et al., 2015; Lillicrap et al., 2016; Haarnoja et al., 2018), has the problem of low-efficiency (Janner et al., 2019), which limits the application in real-world physical systems where data collection can be an arduous process.",RS_125_NeurIPS_2019_08,"Cited Paper: (Janner et al., 2019)",A18LFH7XW61JO9,22,Neutral,A2QD9PJUKW7PKK,68,Negative,A2HM35CWB7IIFM,6,Negative,batch_23,Negative,2,Negative,OK
1607,"Just like learning diffused distribution xt ln p(xt) improves upon direct estimation of x ln p(x) [22, 23], diffusing both the input x and condition y, and then learning xt ln p(xt|yt) could make optimization easier and give better results than learning xt ln p(xt|y) directly.",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,10,Neutral,A2R2YZTSME1K3F,43,Neutral,A2HM35CWB7IIFM,5,Positive,batch_19,Neutral,2,Neutral,OK
1617,"Following [20, 21], validation data are not provided for CV datasets.",RS_102_MLRC_2020_09,First Author: Sohn,A18LFH7XW61JO9,18,Positive,A2QD9PJUKW7PKK,90,Negative,A2HM35CWB7IIFM,5,Negative,batch_13,Negative,2,Negative,OK
1673,Label consistency is a good choice to achieve this goal because it encourages the fine-tuned model to produce the same output when there are minor perturbations in the input [36].,RS_102_MLRC_2020_09,First Author: Sohn,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,12,Neutral,A2QD9PJUKW7PKK,103,Neutral,batch_13,Neutral,2,Neutral,OK
1725,"3, our L2AC provides a relatively balanced per-class recall compared with the baseline FixMatch (Sohn et al., 2020) and other imbalanced SSL methods, e.g., DARP (Kim et al., 2020a) and ABC (Lee et al., 2021).",RS_102_MLRC_2020_09,"Cited Paper: (Sohn et al., 2020)",A18LFH7XW61JO9,11,Positive,A2HM35CWB7IIFM,5,Positive,A2QD9PJUKW7PKK,130,Positive,batch_13,Positive,3,Positive,OK
1781,"Masked autoencoder (MAE) [83] develops an asymmetric encoder-decoder architecture to couple the self-supervised reconstruction and backend training, yielding a promising transfer performance for the downstream tasks.",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,8,Neutral,A2R2YZTSME1K3F,151,Neutral,A3EG4C9T4F5DUR,20,Positive,batch_19,Neutral,2,Neutral,OK
1885,", FixMatch (Sohn et al., 2020), fail in the MNAR scenario.",RS_102_MLRC_2020_09,"Cited Paper: (Sohn et al., 2020)",A2QD9PJUKW7PKK,60,Negative,A2HM35CWB7IIFM,4,Negative,A18LFH7XW61JO9,14,Neutral,batch_13,Negative,2,Negative,OK
1906,MAE [27] proposes an asymmetric encoder-decoder architecture for better efficiency.,RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,32,Neutral,A18LFH7XW61JO9,13,Neutral,A2QD9PJUKW7PKK,178,Neutral,batch_19,Neutral,3,Neutral,OK
1968,"We use two pretrained Masked Autoencoders (He et al., 2022) that are available from their official repository.",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,9,Neutral,A2R2YZTSME1K3F,61,Positive,A2HM35CWB7IIFM,4,Positive,batch_19,Positive,2,Positive,OK
2052,Fixmatch [27] simplifies the learning process by training the model with high-confidence pseudo labels.,RS_102_MLRC_2020_09,First Author: Sohn,A2QD9PJUKW7PKK,67,Neutral,A18LFH7XW61JO9,13,Neutral,A2HM35CWB7IIFM,4,Neutral,batch_13,Neutral,3,Neutral,OK
2132,"Inspired by MAE [10], we propose an augmentation framework named MGPose.",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,18,Positive,A2R2YZTSME1K3F,143,Positive,A2HM35CWB7IIFM,4,Positive,batch_19,Positive,3,Positive,OK
2146,"We implemented the 3D MAE using 3D-ResNetBlocks instead of Vision Transformer, different from the previous study [13], due to the constraint of GPU memory.",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,66,Negative,A18LFH7XW61JO9,11,Positive,A2HM35CWB7IIFM,5,Negative,batch_19,Negative,2,Negative,OK
2195,"However, in the early phase of training, consistency regularization regularizes the model towards high entropy predictions, and prevents it from achieving good accuracy[13].",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,24,Negative,A18LFH7XW61JO9,14,Neutral,A2HM35CWB7IIFM,4,Negative,batch_14,Negative,2,Negative,OK
2249,"While these models can achieve impressive results on many tasks [12], they often require massive amounts of data and computation to train, making them impractical for many real-world applications.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,102,Neutral,A1G94QON7A9K0N,75,Negative,A3EG4C9T4F5DUR,13,Negative,batch_3,Negative,2,Negative,OK
2383,"We train vision transformers (ViT-B and ViT-L) (Dosovitskiy et al., 2020) on these 4 datasets using Masked AutoEncoding (MAE) (He et al., 2021), and systematically analyze their performance on CORTEXBENCH.",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,14,Positive,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,14,Neutral,batch_14,Positive,2,Positive,OK
2453,"Furthermore, we note that our model does not use the [cls] token, unlike the approach by He et al. (2022).",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,9,Negative,A18LFH7XW61JO9,14,Neutral,AKSJ3C5O3V9RB,365,Negative,batch_14,Negative,2,Negative,OK
2475,"Follow MAE (He et al., 2021), we evaluate the performance of the proposed Layer Grafted Pre-training with different number of fixing blocks.",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,78,Positive,A18LFH7XW61JO9,9,Positive,A2HM35CWB7IIFM,5,Positive,batch_19,Positive,3,Positive,OK
2552,We compare the performance of MAE pretraining on the large scale IG-3B with the original MAE [33] models trained on IN1k for 1600 epochs.,RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,9,Positive,A18LFH7XW61JO9,15,Positive,A5V3ZMQI0PU3F,10,Positive,batch_14,Positive,3,Positive,OK
2621,"Surprisingly, when we directly reconstruct masked joints using a method similar to that in MAE [10], the performance degrades instead.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,183,Negative,A1G94QON7A9K0N,16,Negative,A1FVXS8IM5QYO8,4,Negative,batch_3,Negative,3,Negative,OK
2685,"However, we designed FaceMAE, a masked autoencoder [25] specialized for FER-W, by making two major modifications to the original masked autoencoding scheme.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,72,Positive,A18LFH7XW61JO9,24,Positive,A1G94QON7A9K0N,8,Positive,batch_3,Positive,3,Positive,OK
2839,"For all the models involved in the experiments including DeiT (Touvron et al., 2020), MoCo v3 (Chen et al., 2021), DINO (Caron et al., 2021), BEiT (Bao et al., 2021), MAE (He et al., 2021), CAE (Chen et al., 2022a), and iBOT (Zhou et al., 2021), we use their official code to implement the encoders.",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,42,Positive,A1FVXS8IM5QYO8,4,Positive,A2QD9PJUKW7PKK,84,Positive,batch_20,Positive,3,Positive,OK
2944,"Is it possible to reduce the random mask ratio to increase pre-training efficiency and improve consistency? In fact, the prior work [19] already shows that reducing the mask ratio brings lower transfer ability for downstream tasks.",RS_040_MLRC_2022_40,First Author: He,A18LFH7XW61JO9,45,Negative,A1G94QON7A9K0N,25,Negative,A5V3ZMQI0PU3F,62,Neutral,batch_3,Negative,2,Negative,OK
2950,"Second, MAE (He et al, 2022) improves adversarial robustness on ViTs, while MOCOv3 (Chen et al, 2021) benefits adversarial robustness.",RS_102_MLRC_2020_09,First Author: Sohn,A2HM35CWB7IIFM,4,Positive,A3NAHN61XJ3ZAT,11,Neutral,A18LFH7XW61JO9,14,Neutral,batch_14,Neutral,2,Neutral,OK
2958,Different reconstruction results of MAE [19] correspond to different mask seeds.,RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,8,Neutral,A18LFH7XW61JO9,17,Neutral,A5V3ZMQI0PU3F,26,Positive,batch_14,Neutral,2,Neutral,OK
3067,"(Yang et al., 2022)Oriented RCNN ViTAE 81.24 Use MAE (He et al., 2022) to pretrain the plain ViTAE transformer.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A1G94QON7A9K0N,20,Neutral,A18LFH7XW61JO9,13,Positive,A5V3ZMQI0PU3F,63,Neutral,batch_3,Neutral,2,Neutral,OK
3177,"For our experiments, we use the CNN feature map (Santoro et al., 2017; Zambaldi et al., 2018) for end-to-end learned fixedregion representations and the mini-patch representations from pre-trained Masked AutoEncoder (MAE) (He et al., 2022) for pre-trained fixed-region representations.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A1G94QON7A9K0N,24,Positive,A18LFH7XW61JO9,12,Positive,A5V3ZMQI0PU3F,28,Positive,batch_3,Positive,3,Positive,OK
3219,"Patch-based masking methods for self-supervised learning (Bao et al., 2022; He et al., 2021; El-Nouby et al., 2021a) have recently demonstrated their potential for image generation (Chang et al.",RS_120_NeurIPS_2019_03,First Author: Song,A18LFH7XW61JO9,8,Neutral,A1G94QON7A9K0N,7,Neutral,A3EG4C9T4F5DUR,17,Positive,batch_20,Neutral,2,Neutral,OK
3256,"Different from models like MAE He et al. (2022) and SimMIM Xie et al. (2022) that are specifically tailored for particular network architectures, our framework can be seamlessly applied to any deep vision models without any customization or auxiliary network components beside the simple linear head",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,131,Neutral,A18LFH7XW61JO9,20,Positive,A1G94QON7A9K0N,22,Positive,batch_3,Positive,2,Neutral,ISSUE
3325,"The algorithms include MoCo-v2 (He et al., 2020), MoCo-v3 (Chen et al., 2021a), InstDisc (Wu et al., 2018), BYOL (Grill et al., 2020), SwAV (Caron et al., 2020), OBoW (Gidaris et al., 2021), SimSiam (Chen & He, 2021), Barlow Twins (Zbontar et al., 2021), DINO (Caron et al., 2021), MAE (He et al., 2022), iBOT (Zhou et al., 2022) and EsViT (Li et al., 2022a).",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2020)",A2QD9PJUKW7PKK,146,Neutral,A18LFH7XW61JO9,14,Neutral,A1G94QON7A9K0N,13,Neutral,batch_3,Neutral,3,Neutral,OK
3354,"It means that our RangeViT approach, by being able to use off-the-shelf pre-trained ViT models, can directly benefit from current and future advances on the training ViT models with natural RGB images, a very active and rapidly growing research field [22, 39, 46, 47].",RS_040_MLRC_2022_40,First Author: He,A1G94QON7A9K0N,30,Positive,A2QD9PJUKW7PKK,289,Positive,A18LFH7XW61JO9,11,Neutral,batch_3,Positive,2,Neutral,ISSUE
3467," Representations learned by offline Q-learning give rise to more than 80% better performance when fine-tuning on new games compared to representations from state-of-the-art returnconditioned supervised (Lee et al., 2022) and self-supervised methods (He et al., 2021; Oord et al., 2018).",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,53,Neutral,A18LFH7XW61JO9,33,Positive,A2QD9PJUKW7PKK,79,Positive,batch_20,Positive,2,Positive,OK
3559,We retrained the CSWin transformer without redesign and original transformer [9] separately and compared them with our redesigned,RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,28,Positive,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,15,Positive,batch_14,Positive,3,Positive,OK
3578,"Similarly, while layer-wise lr decay improved the performance of high-level vision tasks when fine-tuning Transformer models [6, 25], our models could not learn the representations well with that regularization.",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,52,Negative,A2QD9PJUKW7PKK,53,Negative,A1G94QON7A9K0N,8,Negative,batch_20,Negative,3,Negative,OK
3673,"Importantly, our method is also effective for self-supervised learning (e.g., MAE [22]).",RS_120_NeurIPS_2019_03,First Author: Song,A2QD9PJUKW7PKK,47,Positive,A18LFH7XW61JO9,6,Neutral,A2R2YZTSME1K3F,35,Positive,batch_20,Positive,2,Neutral,ISSUE
3723,"However, in general MAE is performing worse than other SSL methods on linear probing (see Table III), which has also been reported in recent works [41, 42].",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,49,Neutral,A2QD9PJUKW7PKK,625,Negative,A3EG4C9T4F5DUR,920,Negative,batch_20,Negative,2,Negative,OK
3726,"Furthermore, inspired by He et al. (2021), we explore enhancing the visual encoder via randomly masking the input image tokens and then reconstructing them, which can help reduce the computation cost during training and boost visual embedding by maintaining low-level visual information.",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,14,Neutral,A18LFH7XW61JO9,14,Positive,A5V3ZMQI0PU3F,18,Positive,batch_14,Positive,2,Positive,OK
3733,"Recent years have seen the rapid proliferation of vision transformers (ViTs) across a diverse range of tasks from image classification to semantic segmentation to object detection (Dosovitskiy et al., 2020; He et al., 2021; Dong et al., 2021; Liu et al., 2021; Zhai et al., 2021; Dai et al., 2021).",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,7,Neutral,A18LFH7XW61JO9,18,Neutral,A5V3ZMQI0PU3F,16,Neutral,batch_14,Neutral,3,Neutral,OK
3774,"Inspired by the representation bottleneck and the mask-based method MAE [45], we propose a training",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,62,Neutral,A1G94QON7A9K0N,13,Positive,A37WXDYYT7RCZ0,3,Neutral,batch_3,Neutral,2,Neutral,OK
3834,"Indeed, we have observed that freezing the backbone and training a linear classifier on top of MAE features perform very poorly [34].",RS_040_MLRC_2022_40,First Author: He,A2HM35CWB7IIFM,6,Negative,A18LFH7XW61JO9,14,Negative,A2QD9PJUKW7PKK,116,Negative,batch_4,Negative,3,Negative,OK
3870,"We hypothesize that the object-reasoning-like behaviour demonstrated to appear in the self-supervision task of masked image modelling [2, 3] can be utilized also for explicit object-centric representation learning.",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,81,Neutral,A18LFH7XW61JO9,21,Neutral,A1G94QON7A9K0N,7,Positive,batch_20,Neutral,2,Neutral,OK
4003,"For the low-level target, ViT (Dosovitskiy et al., 2020), MAE (He et al., 2022), SimMIM (Liu et al., 2022b), ConvMAE (Gao et al., 2022), HiViT (Zhang et al., 2022) and GreenMIM (Huang et al., 2022) utilize the original or normalized pixels as the MIM target.",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,38,Neutral,A18LFH7XW61JO9,6,Neutral,A37WXDYYT7RCZ0,5,Neutral,batch_20,Neutral,3,Neutral,OK
4006,"Following MAE (He et al., 2022) and BEiT v2 (Peng et al., 2022), we test the robustness of MaskDistill on three ImageNet validation sets, i.e., ImageNet-Adversarial (Hendrycks et al., 2021b), ImageNet-Rendition (Hendrycks et al., 2021a) and ImageNet-Sketch (Wang et al., 2019).",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,191,Positive,A2QD9PJUKW7PKK,43,Positive,A18LFH7XW61JO9,12,Positive,batch_20,Positive,3,Positive,OK
4030,"Unfortunately, this setting may entail a long training epoch in PlantCLEF2022 to have a better performance, such as 800 epochs in MAE (He et al., 2022).",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A18LFH7XW61JO9,12,Neutral,A2HM35CWB7IIFM,4,Negative,A2QD9PJUKW7PKK,270,Negative,batch_4,Negative,2,Negative,OK
4193,"However, due to the low information density of image data [20, 44], there is still much noisy and redundant information after their proposed augmentation, which would affect the extraction of desired information and thus limit the performance of CL in practice.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,277,Negative,A18LFH7XW61JO9,13,Neutral,A3NAHN61XJ3ZAT,36,Negative,batch_4,Negative,2,Negative,OK
4207,3 improvement on AP bbox than MAE [20] (53.,RS_102_MLRC_2020_09,First Author: Sohn,AKSJ3C5O3V9RB,902,Neutral,A2QD9PJUKW7PKK,16,Positive,A18LFH7XW61JO9,8,Neutral,batch_15,Neutral,2,Neutral,OK
4214,"However, in general MAE is performing worse than other SSL methods on linear probing (see Table III), which has also been reported in recent works [41, 42].",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,62,Neutral,A18LFH7XW61JO9,15,Negative,A3NAHN61XJ3ZAT,9,Neutral,batch_4,Neutral,2,Neutral,OK
4220,"We also adopt an asymmetric architecture as in [18]: the encoder is optimized to learn effective fMRI representations, while the decoder tries to predict the masked patches.",RS_102_MLRC_2020_09,First Author: Sohn,A2QD9PJUKW7PKK,68,Positive,A2HM35CWB7IIFM,5,Positive,AJ0RL2YCXZC25,42,Neutral,batch_15,Positive,2,Positive,OK
4253,"The weight decay is set to zero, following the setups in MAE [20].",RS_102_MLRC_2020_09,First Author: Sohn,AKSJ3C5O3V9RB,799,Positive,A18LFH7XW61JO9,17,Positive,A2HM35CWB7IIFM,4,Positive,batch_15,Positive,3,Positive,OK
4291,"Like MAE [10], each encoder in our approach maps the partially observed signal to the latent representation, which has been approved to be effective to learn object semantics",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,74,Neutral,A18LFH7XW61JO9,9,Positive,A3NAHN61XJ3ZAT,7,Neutral,batch_4,Neutral,2,Neutral,OK
4298,"1) Black-Box Attack: For the attack model, we adopt a similar structure to the edge model: an MAE decoder [18] is used, and is pretrained on ImageNet.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,1281,Positive,A3NAHN61XJ3ZAT,10,Positive,A18LFH7XW61JO9,16,Positive,batch_4,Positive,3,Positive,OK
4326,"BERT (Kenton and Toutanova, 2019) and MAE (He et al., 2022), to classification tasks in NLP, the linear probing performs poorly because the extracted features are specialized for mask prediction and might not contain enough information for classification (Wallat et al.",RS_102_MLRC_2020_09,First Author: Sohn,A3NAHN61XJ3ZAT,12,Negative,A18LFH7XW61JO9,9,Neutral,A2HM35CWB7IIFM,4,Negative,batch_15,Negative,2,Negative,OK
4441,"Another exception is the masked auto-enconder [60] based on the ViT backbone, where we place SSPCAB and SSMCTB before the first transformer block.",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,52,Positive,A18LFH7XW61JO9,8,Neutral,A2QD9PJUKW7PKK,48,Neutral,batch_21,Neutral,2,Neutral,OK
4469," We show that block-wise masking provides superior performance on Masked Siamese ConvNets to the discrete random masking, commonly used in selfsupervised representation learning frameworks [20, 24, 1].",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,77,Neutral,A18LFH7XW61JO9,17,Neutral,A3NAHN61XJ3ZAT,19,Neutral,batch_4,Neutral,3,Neutral,OK
4537,"Table 1: Token Merging ablation experiments using ViT-L/16 from MAE (He et al., 2022) on ImageNet-1k evaluated off-the-shelf without training, using r = 8.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A2QD9PJUKW7PKK,73,Neutral,A18LFH7XW61JO9,13,Positive,AKSJ3C5O3V9RB,34454,Positive,batch_4,Positive,2,Positive,OK
4541,"We follow the exact same protocol as MAE [38] for that, with global average pooling for CroCo as we did not include a [CLS] token in our model.",RS_102_MLRC_2020_09,First Author: Sohn,A18LFH7XW61JO9,16,Positive,A2HM35CWB7IIFM,4,Positive,A3NAHN61XJ3ZAT,11,Positive,batch_15,Positive,3,Positive,OK
4653,"In the absence of prior work applying masked autoencoding to abstract/synthetic imagery, we explore a large masked pixel percentage (75% of the image), thus forcing the model to attempt to recover the image based only on the unmasked 25% of the image, such high percentages have been shown to work well for natural imagery [30].",RS_120_NeurIPS_2019_03,First Author: Song,A2R2YZTSME1K3F,48,Positive,A18LFH7XW61JO9,9,Neutral,A1IXVXZ5AYYNMJ,19,Positive,batch_21,Positive,2,Positive,OK
4712,"Our decoder is another vanilla ViT deployed on the union of the encoded patch set and a set of mask tokens (He et al., 2022).",RS_102_MLRC_2020_09,First Author: Sohn,A2HM35CWB7IIFM,3,Positive,A18LFH7XW61JO9,10,Neutral,A3NAHN61XJ3ZAT,7,Neutral,batch_15,Neutral,2,Neutral,OK
4724,"We fine-tune a stateof-the-art vision transformer model pretrained with masked autoencoding (He et al., 2021) for 100 epochs on rotated MNIST (Weiler and Cesa, 2019) (details in Appendix C.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2021)",A2QD9PJUKW7PKK,49,Positive,A2HM35CWB7IIFM,4,Positive,A18LFH7XW61JO9,12,Positive,batch_4,Positive,3,Positive,OK
4840,"He et al., 2022) and VideoMAE (Tong et al., 2022) to conduct further comparison on video and image datasets, which follows the self-supervised pre-training setting2 in S. Chen et al. (2022) except that the batch size is set to 256 instead of 1, 024.",RS_102_MLRC_2020_09,First Author: Sohn,A18LFH7XW61JO9,12,Positive,A2HM35CWB7IIFM,4,Positive,A5V3ZMQI0PU3F,85,Neutral,batch_15,Positive,2,Positive,OK
5027,"Different from existing works that focus on MVM for pure vision problems [4, 22, 86], we study MVM as a VidL pre-training task.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,110,Positive,A2HM35CWB7IIFM,5,Positive,A3NAHN61XJ3ZAT,8,Neutral,batch_4,Positive,2,Positive,OK
5630,"For the MAE, we only modified its input size of the ViT model in its encoder and decoder (from 224 to 512), and other model details are the same as those in [10].",RS_040_MLRC_2022_40,First Author: He,A2HM35CWB7IIFM,5,Positive,A18LFH7XW61JO9,21,Positive,A5V3ZMQI0PU3F,23,Positive,batch_5,Positive,3,Positive,OK
5814,"rying out the masked image modeling task (He et al., 2022; Xie et al., 2022).",RS_040_MLRC_2022_40,First Author: He,A18LFH7XW61JO9,14,Neutral,A5V3ZMQI0PU3F,8,Neutral,A2HM35CWB7IIFM,5,Neutral,batch_5,Neutral,3,Neutral,OK
5913,"Unlike MAE (He et al., 2021) that shuffles or unshuffles the token list, we gather the vector of target patches in the correct order.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2021)",A18LFH7XW61JO9,11,Positive,A2QD9PJUKW7PKK,881,Neutral,A3NAHN61XJ3ZAT,7,Neutral,batch_5,Neutral,2,Neutral,OK
6159,"Compared with MAE-Base [26], ConvMAE-Base improves the ImageNet-1K finetuning accuracy to 85.",RS_040_MLRC_2022_40,First Author: He,A18LFH7XW61JO9,15,Positive,A2HM35CWB7IIFM,5,Positive,A3NAHN61XJ3ZAT,9,Neutral,batch_5,Positive,2,Positive,OK
6326,The ViT models are pre-trained using MAE [23] on IN-1K.,RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,44,Positive,A3NAHN61XJ3ZAT,6,Neutral,A2HM35CWB7IIFM,5,Positive,batch_5,Positive,2,Positive,OK
6924,"The original MAE [16] masks random patches of the input image, but the same strategy is not suitable for our DeepfakeMAE for the following reasons.",RS_040_MLRC_2022_40,First Author: He,A3NAHN61XJ3ZAT,10,Negative,A18LFH7XW61JO9,12,Positive,A2HM35CWB7IIFM,7,Negative,batch_5,Negative,2,Negative,OK
7078,"This random masking strategy is also consistent with pioneering self-supervised learning approaches that conjugate masked image modeling with the ViT models in a patch-wise manner (Bao et al., 2021; He et al., 2022; Xie et al., 2022).",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,85,Neutral,A3NAHN61XJ3ZAT,7,Neutral,A2HM35CWB7IIFM,4,Positive,batch_5,Neutral,2,Neutral,OK
7082,"We compare ViT-B trained by different methods: supervised model (ERM), multimodal learning - CLIP (Radford et al., 2021), and self-supervised learning - DINO (Caron et al., 2021) and MAE (He et al., 2022).",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A3NAHN61XJ3ZAT,14,Positive,A2HM35CWB7IIFM,6,Positive,A2QD9PJUKW7PKK,1252,Positive,batch_5,Positive,3,Positive,OK
7098,"However, the encoder for MAE is a vision transformer [56], which is not suitable for processing high-resolution SAR images due to its huge memory usage.",RS_040_MLRC_2022_40,First Author: He,A2HM35CWB7IIFM,6,Negative,A18LFH7XW61JO9,13,Negative,A2QD9PJUKW7PKK,23123,Negative,batch_5,Negative,3,Negative,OK
7185,"Inspired by MAE (He et al., 2022), we observe a different information density between sentences and documents  for an event, most parts of the document are irrelevant, leading to a low information density.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2022)",A3NAHN61XJ3ZAT,18,Negative,AKSJ3C5O3V9RB,4886,Negative,A27PVIL93ZMY46,182,Positive,batch_5,Negative,2,Negative,OK
7215,"It is further MAE fine-tuned (He et al., 2021), using the same in-domain data as for the Mask R-CNN object detector.",RS_040_MLRC_2022_40,"Cited Paper: (He et al., 2021)",A2QD9PJUKW7PKK,83,Positive,A1G94QON7A9K0N,38,Positive,A2HM35CWB7IIFM,4,Positive,batch_6,Positive,3,Positive,OK
7373,"Unlike MAE [9], the reconstruction target for large-scale point clouds is set to whether the voxel contains the point clouds, and the Encoder is built with the 3D Spatially Sparse Convolutions to handle the large-scale unmasked voxels.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,142,Neutral,A2HM35CWB7IIFM,4,Positive,A3NAHN61XJ3ZAT,23,Neutral,batch_6,Neutral,2,Neutral,OK
7648,"Similarly as [30], we employ random masking of 75% of the patches.",RS_040_MLRC_2022_40,First Author: He,A37WXDYYT7RCZ0,3,Neutral,AJ0RL2YCXZC25,15,Positive,A2HM35CWB7IIFM,4,Positive,batch_6,Positive,2,Positive,OK
7689,"Inspired by the form of the training sample, we propose the center-masked pre-training task, which is similar to MAE [18] but our method is easier to implement.",RS_040_MLRC_2022_40,First Author: He,A2QD9PJUKW7PKK,140,Positive,A2HM35CWB7IIFM,4,Positive,AJ0RL2YCXZC25,24,Positive,batch_6,Positive,3,Positive,OK